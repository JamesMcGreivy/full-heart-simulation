{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the points, surfaces, tetrahedra, and UVCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading points from /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.pts\n",
      "Loaded 110822 points with shape (110822, 3)\n",
      "Reading tetrahedra from /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.elem\n",
      "Loaded 567173 tetrahedra with shape (567173, 4)\n",
      "Reading triangles from /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.surf\n",
      "Loaded 77128 triangles with shape (77128, 3)\n",
      "Reading UVC data from /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/UVC_heart_instance_001_lowres.csv\n",
      "Loaded UVC data with shape (110822, 6)\n",
      "UVC columns: ['tv', 'tm', 'rtSin', 'rtCos', 'rt', 'ab']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "class OpenCARPMeshReader:\n",
    "    \"\"\"\n",
    "    Class to read openCARP mesh files (.pts, .elem, .surf) and UVC data (.csv)\n",
    "    and convert them to NumPy arrays and pandas DataFrames.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir, prefix):\n",
    "        \"\"\"\n",
    "        Initialize the reader with the directory and file prefix.\n",
    "        \n",
    "        Args:\n",
    "            base_dir (str): Directory containing the mesh files\n",
    "            prefix (str): Prefix for the mesh files (e.g., 'heart_instance_001')\n",
    "        \"\"\"\n",
    "        self.base_dir = base_dir\n",
    "        self.prefix = prefix\n",
    "        \n",
    "        # Set file paths\n",
    "        self.pts_file = os.path.join(base_dir, f\"{prefix}.pts\")\n",
    "        self.elem_file = os.path.join(base_dir, f\"{prefix}.elem\")\n",
    "        self.surf_file = os.path.join(base_dir, f\"{prefix}.surf\")\n",
    "        self.uvc_file = os.path.join(base_dir, f\"UVC_{prefix}.csv\")\n",
    "        \n",
    "        # Storage for mesh components\n",
    "        self.points = None\n",
    "        self.tetrahedra = None\n",
    "        self.triangles = None\n",
    "        self.triangle_regions = None\n",
    "        self.tetrahedra_regions = None\n",
    "        self.uvc_data = None\n",
    "    \n",
    "    def read_points(self):\n",
    "        \"\"\"\n",
    "        Read the .pts file and return an array of points with dimension (n_points x 3).\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Array of 3D points\n",
    "        \"\"\"\n",
    "        print(f\"Reading points from {self.pts_file}\")\n",
    "        \n",
    "        with open(self.pts_file, 'r') as f:\n",
    "            # Read the number of points from the first line\n",
    "            n_points = int(f.readline().strip())\n",
    "            \n",
    "            # Initialize the points array\n",
    "            points = np.zeros((n_points, 3))\n",
    "            \n",
    "            # Read each point\n",
    "            for i in range(n_points):\n",
    "                line = f.readline().strip()\n",
    "                # Parse x, y, z coordinates\n",
    "                x, y, z = map(float, line.split())\n",
    "                points[i] = [x, y, z]\n",
    "        \n",
    "        self.points = points\n",
    "        print(f\"Loaded {n_points} points with shape {points.shape}\")\n",
    "        return points\n",
    "    \n",
    "    def read_tetrahedra(self):\n",
    "        \"\"\"\n",
    "        Read the .elem file and return an array of tetrahedra with dimension (n_tetrahedra x 4).\n",
    "        Each tetrahedron contains indices to the points array.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Array of tetrahedra indices\n",
    "            numpy.ndarray: Array of region IDs for each tetrahedron\n",
    "        \"\"\"\n",
    "        print(f\"Reading tetrahedra from {self.elem_file}\")\n",
    "        \n",
    "        tetrahedra = []\n",
    "        tetrahedra_regions = []\n",
    "        \n",
    "        with open(self.elem_file, 'r') as f:\n",
    "            # Read the number of elements from the first line\n",
    "            n_elements = int(f.readline().strip())\n",
    "            \n",
    "            # Read each tetrahedron\n",
    "            for i in range(n_elements):\n",
    "                line = f.readline().strip()\n",
    "                \n",
    "                # Parse the line for a tetrahedron (Tt format)\n",
    "                if line.startswith('Tt'):\n",
    "                    parts = line.split()\n",
    "                    \n",
    "                    # Extract the 4 vertex indices\n",
    "                    indices = [int(parts[1]), int(parts[2]), int(parts[3]), int(parts[4])]\n",
    "                    \n",
    "                    # Extract region ID (if available)\n",
    "                    region_id = int(parts[5]) if len(parts) > 5 else 0\n",
    "                    \n",
    "                    tetrahedra.append(indices)\n",
    "                    tetrahedra_regions.append(region_id)\n",
    "        \n",
    "        # Convert to NumPy arrays\n",
    "        tetrahedra = np.array(tetrahedra)\n",
    "        tetrahedra_regions = np.array(tetrahedra_regions)\n",
    "        \n",
    "        self.tetrahedra = tetrahedra\n",
    "        self.tetrahedra_regions = tetrahedra_regions\n",
    "        \n",
    "        print(f\"Loaded {len(tetrahedra)} tetrahedra with shape {tetrahedra.shape}\")\n",
    "        return tetrahedra, tetrahedra_regions\n",
    "    \n",
    "    def read_triangles(self):\n",
    "        \"\"\"\n",
    "        Read the .surf file and return an array of triangles with dimension (n_triangles x 3).\n",
    "        Each triangle contains indices to the points array.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Array of triangle indices\n",
    "            numpy.ndarray: Array of region IDs for each triangle\n",
    "        \"\"\"\n",
    "        print(f\"Reading triangles from {self.surf_file}\")\n",
    "        \n",
    "        triangles = []\n",
    "        triangle_regions = []\n",
    "        \n",
    "        with open(self.surf_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(lines):\n",
    "                line = lines[i].strip()\n",
    "                i += 1\n",
    "                \n",
    "                # Check if this line defines a region\n",
    "                region_match = re.match(r\"(\\d+)(?:\\s+Reg\\s+(\\d+))?\", line)\n",
    "                if region_match:\n",
    "                    n_triangles_in_region = int(region_match.group(1))\n",
    "                    \n",
    "                    if region_match.group(2):\n",
    "                        region_id = int(region_match.group(2))\n",
    "                    else:\n",
    "                        region_id = -1\n",
    "                    \n",
    "                    # Read triangles for this region\n",
    "                    for j in range(n_triangles_in_region):\n",
    "                        if i < len(lines):\n",
    "                            tri_line = lines[i].strip()\n",
    "                            i += 1\n",
    "                            \n",
    "                            # Parse triangle (Tr format)\n",
    "                            if tri_line.startswith('Tr'):\n",
    "                                parts = tri_line.split()\n",
    "                                # Extract the 3 vertex indices\n",
    "                                indices = [int(parts[1]), int(parts[2]), int(parts[3])]\n",
    "                                \n",
    "                                triangles.append(indices)\n",
    "                                triangle_regions.append(region_id)\n",
    "        \n",
    "        # Convert to NumPy arrays\n",
    "        triangles = np.array(triangles)\n",
    "        triangle_regions = np.array(triangle_regions)\n",
    "        \n",
    "        self.triangles = triangles\n",
    "        self.triangle_regions = triangle_regions\n",
    "        \n",
    "        print(f\"Loaded {len(triangles)} triangles with shape {triangles.shape}\")\n",
    "        return triangles, triangle_regions\n",
    "    \n",
    "    def read_uvc_data(self):\n",
    "        \"\"\"\n",
    "        Read the UVC data from the CSV file into a pandas DataFrame.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame containing UVC data\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.uvc_file):\n",
    "            print(f\"Reading UVC data from {self.uvc_file}\")\n",
    "            \n",
    "            # Read the CSV file into a pandas DataFrame\n",
    "            uvc_data = pd.read_csv(self.uvc_file)\n",
    "            \n",
    "            self.uvc_data = uvc_data\n",
    "            \n",
    "            print(f\"Loaded UVC data with shape {uvc_data.shape}\")\n",
    "            print(f\"UVC columns: {uvc_data.columns.tolist()}\")\n",
    "            \n",
    "            return uvc_data\n",
    "        else:\n",
    "            print(f\"UVC file not found: {self.uvc_file}\")\n",
    "            return None\n",
    "    \n",
    "    def read_all(self):\n",
    "        \"\"\"\n",
    "        Read all mesh files and UVC data.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (points, tetrahedra, tetrahedra_regions, triangles, triangle_regions, uvc_data)\n",
    "        \"\"\"\n",
    "        points = self.read_points()\n",
    "        tetrahedra, tetrahedra_regions = self.read_tetrahedra()\n",
    "        triangles, triangle_regions = self.read_triangles()\n",
    "        uvc_data = self.read_uvc_data()\n",
    "        \n",
    "        return (points, tetrahedra, tetrahedra_regions, triangles, triangle_regions, uvc_data)\n",
    "\n",
    "data_path = \"/Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/\"\n",
    "output_prefix = \"heart_instance_001_lowres\"\n",
    "reader = OpenCARPMeshReader(data_path, output_prefix)\n",
    "points, tetrahedra, tetrahedra_regions, triangles, triangle_regions, uvc_data = reader.read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import pyvista as pv\n",
    "\n",
    "def compute_normed_gradients(points, phi_transmural, phi_longitudinal, phi_circumferential):\n",
    "    \"\"\"Compute normalized gradient of phi.\"\"\"\n",
    "    from scipy.spatial import KDTree\n",
    "    \n",
    "    tree = KDTree(points)\n",
    "    grad_phi_transmural = np.zeros_like(points)\n",
    "    grad_phi_longitudinal = np.zeros_like(points)\n",
    "    grad_phi_circumferential = np.zeros_like(points)\n",
    "    \n",
    "    for i, p in enumerate(points):\n",
    "        _, neighbors = tree.query(p, k=20)  # Find nearby points\n",
    "        \n",
    "        neighbor_points = points[neighbors]\n",
    "        \n",
    "        neighbor_phi_transmural = phi_transmural[neighbors]\n",
    "        grad = np.linalg.lstsq(neighbor_points - p, neighbor_phi_transmural - phi_transmural[i], rcond=None)[0]\n",
    "        grad_phi_transmural[i] = grad / (1e-9 + np.linalg.norm(grad))  # Normalize\n",
    "\n",
    "        neighbor_phi_longitudinal = phi_longitudinal[neighbors]\n",
    "        grad = np.linalg.lstsq(neighbor_points - p, neighbor_phi_longitudinal - phi_longitudinal[i], rcond=None)[0]\n",
    "        grad_phi_longitudinal[i] = grad / (1e-9 + np.linalg.norm(grad))  # Normalize\n",
    "\n",
    "        neighbor_phi_circumferential = phi_circumferential[neighbors]\n",
    "        grad = np.linalg.lstsq(neighbor_points - p, neighbor_phi_circumferential - phi_circumferential[i], rcond=None)[0]\n",
    "        grad_phi_circumferential[i] = grad / (1e-9 + np.linalg.norm(grad))  # Normalize\n",
    "    \n",
    "    return grad_phi_transmural, grad_phi_longitudinal, grad_phi_circumferential\n",
    "\n",
    "phi_transmural = np.array(uvc_data['tm'])\n",
    "phi_longitudinal = np.array(uvc_data['ab'])\n",
    "phi_circumferential = np.array(uvc_data[\"rt\"])\n",
    "TransmuralField, LongitudinalField, CircumferentialField = compute_normed_gradients(points, -phi_transmural, -phi_longitudinal, phi_circumferential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original points: 110822\n",
      "Original triangles: 77128\n",
      "Epicardium triangles: 35848\n",
      "Endocardium triangles: 39581\n",
      "Sampled epicardium points: 180\n",
      "Sampled endocardium points: 199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a681cf52f72c4d358a84994a18c41f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:63147/index.html?ui=P_0x1422263b0_0&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "from pyvista import themes\n",
    "import os\n",
    "import random\n",
    "\n",
    "def visualize_vector_fields(points, triangles, triangle_regions, \n",
    "                           transmural_field, longitudinal_field, circumferential_field, \n",
    "                           subsample_factor=20, glyph_scale=0.005):\n",
    "    \"\"\"\n",
    "    Create side-by-side visualizations of the vector fields on epicardium and endocardium.\n",
    "    \n",
    "    Left plot: Epicardium (triangle_regions == 2)\n",
    "    Right plot: Endocardium (triangle_regions == 3 or 4)\n",
    "    \"\"\"\n",
    "    # Set up a nice theme for visualization\n",
    "    my_theme = themes.DarkTheme()\n",
    "    my_theme.lighting = True\n",
    "    my_theme.show_edges = False\n",
    "    my_theme.background = 'white'\n",
    "    my_theme.window_size = [1600, 800]\n",
    "    pv.set_plot_theme(my_theme)\n",
    "    \n",
    "    print(f\"Original points: {len(points)}\")\n",
    "    print(f\"Original triangles: {len(triangles)}\")\n",
    "    \n",
    "    # Prepare triangle cells for PyVista format\n",
    "    triangle_cells = np.column_stack(\n",
    "        (np.full(len(triangles), 3), triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    # Create full mesh\n",
    "    full_mesh = pv.PolyData(points, triangle_cells)\n",
    "    \n",
    "    # Create a plotter with two side-by-side viewports\n",
    "    plotter = pv.Plotter(shape=(1, 2))\n",
    "    \n",
    "    # Filter triangles by region\n",
    "    epicardium_triangles = triangles[np.logical_or(triangle_regions == 2, triangle_regions == -1)]\n",
    "    endocardium_triangles = triangles[np.logical_or(triangle_regions == 3, np.logical_or(triangle_regions == 4, triangle_regions == -1))]\n",
    "    \n",
    "    print(f\"Epicardium triangles: {len(epicardium_triangles)}\")\n",
    "    print(f\"Endocardium triangles: {len(endocardium_triangles)}\")\n",
    "    \n",
    "    # Create separate meshes for each surface\n",
    "    epicardium_cells = np.column_stack(\n",
    "        (np.full(len(epicardium_triangles), 3), epicardium_triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    endocardium_cells = np.column_stack(\n",
    "        (np.full(len(endocardium_triangles), 3), endocardium_triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    epicardium_mesh = pv.PolyData(points, epicardium_cells)\n",
    "    endocardium_mesh = pv.PolyData(points, endocardium_cells)\n",
    "    \n",
    "    # Function to sample points from a mesh\n",
    "    def create_sampled_vectors(mesh, field_names=[\"transmural\", \"longitudinal\", \"circumferential\"]):\n",
    "        # Extract unique points from this mesh\n",
    "        unique_point_ids = np.unique(mesh.faces.reshape(-1, 4)[:, 1:].flatten())\n",
    "        \n",
    "        # Further sample to reduce number of arrows\n",
    "        n_sample = min(len(unique_point_ids), len(unique_point_ids) // subsample_factor)\n",
    "        sample_indices = sorted(random.sample(list(unique_point_ids), n_sample))\n",
    "        \n",
    "        # Create a point cloud with the sampled points\n",
    "        sampled_points = points[sample_indices]\n",
    "        point_cloud = pv.PolyData(sampled_points)\n",
    "        \n",
    "        # Add vector data\n",
    "        point_cloud[\"transmural\"] = transmural_field[sample_indices]\n",
    "        point_cloud[\"longitudinal\"] = longitudinal_field[sample_indices]\n",
    "        point_cloud[\"circumferential\"] = circumferential_field[sample_indices]\n",
    "        \n",
    "        return point_cloud, sample_indices\n",
    "    \n",
    "    # Create sampled vector fields for each surface\n",
    "    epicardium_vectors, epi_indices = create_sampled_vectors(epicardium_mesh)\n",
    "    endocardium_vectors, endo_indices = create_sampled_vectors(endocardium_mesh)\n",
    "    \n",
    "    print(f\"Sampled epicardium points: {epicardium_vectors.n_points}\")\n",
    "    print(f\"Sampled endocardium points: {endocardium_vectors.n_points}\")\n",
    "    \n",
    "    # Left viewport: Epicardium\n",
    "    plotter.subplot(0, 0)\n",
    "    plotter.add_text(\"Epicardium Vector Fields\", font_size=16, color=\"black\")\n",
    "    \n",
    "    # Add epicardium surface\n",
    "    plotter.add_mesh(epicardium_mesh, color='lightgray', opacity=0.8)\n",
    "    \n",
    "    # Add vector fields for epicardium\n",
    "    transmural_arrows = epicardium_vectors.glyph(\n",
    "        orient=\"transmural\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(transmural_arrows, color=\"red\", label=\"Transmural\")\n",
    "    \n",
    "    longitudinal_arrows = epicardium_vectors.glyph(\n",
    "        orient=\"longitudinal\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(longitudinal_arrows, color=\"green\", label=\"Longitudinal\")\n",
    "    \n",
    "    circumferential_arrows = epicardium_vectors.glyph(\n",
    "        orient=\"circumferential\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(circumferential_arrows, color=\"blue\", label=\"Circumferential\")\n",
    "    \n",
    "    # Add legend\n",
    "    plotter.add_legend(size=(0.2, 0.2), loc='upper right')\n",
    "    \n",
    "    # Right viewport: Endocardium\n",
    "    plotter.subplot(0, 1)\n",
    "    plotter.add_text(\"Endocardium Vector Fields\", font_size=16, color=\"black\")\n",
    "    \n",
    "    # Add endocardium surface\n",
    "    plotter.add_mesh(endocardium_mesh, color='lightgray', opacity=0.8)\n",
    "    \n",
    "    # Add vector fields for endocardium\n",
    "    transmural_arrows = endocardium_vectors.glyph(\n",
    "        orient=\"transmural\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(transmural_arrows, color=\"red\", label=\"Transmural\")\n",
    "    \n",
    "    longitudinal_arrows = endocardium_vectors.glyph(\n",
    "        orient=\"longitudinal\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(longitudinal_arrows, color=\"green\", label=\"Longitudinal\")\n",
    "    \n",
    "    circumferential_arrows = endocardium_vectors.glyph(\n",
    "        orient=\"circumferential\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(circumferential_arrows, color=\"blue\", label=\"Circumferential\")\n",
    "    \n",
    "    # Add legend\n",
    "    plotter.add_legend(size=(0.2, 0.2), loc='upper right')\n",
    "    \n",
    "    # Link the cameras between the two viewports\n",
    "    plotter.link_views()\n",
    "    \n",
    "    # Set camera position\n",
    "    plotter.camera_position = 'xz'\n",
    "    plotter.camera.zoom(1.2)\n",
    "    \n",
    "    # Show the plot\n",
    "    plotter.show()\n",
    "\n",
    "    plotter.screenshot('../figures/cardial_coordinates.png')\n",
    "\n",
    "# Visualize the fields\n",
    "visualize_vector_fields(\n",
    "    points, triangles, triangle_regions,\n",
    "    TransmuralField, LongitudinalField, CircumferentialField, subsample_factor=100, glyph_scale=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum dot products: (np.float64(1.1879386363489175e-14), np.float64(2.220446049250313e-16), np.float64(1.8735013540549517e-16))\n",
      "Minimum right-hand system alignment: 0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_fiber_sheet_directions(TransmuralField, LongitudinalField, CircumferentialField, phi_transmural):\n",
    "    \"\"\"\n",
    "    Compute rule-based cardiac fiber and sheet directions.\n",
    "    \n",
    "    The fiber angles rotate from +60° at the endocardium (phi=0) to -60° at the epicardium (phi=1).\n",
    "    The sheet angles rotate from -65° at the endocardium to +25° at the epicardium.\n",
    "    \"\"\"\n",
    "    # Number of points\n",
    "    n_points = len(TransmuralField)\n",
    "    \n",
    "    # Initialize output arrays\n",
    "    fiber_directions = np.zeros_like(TransmuralField)\n",
    "    sheet_directions = np.zeros_like(TransmuralField)\n",
    "    sheet_normal_directions = np.zeros_like(TransmuralField)\n",
    "    \n",
    "    # Fiber angle parameters (in radians)\n",
    "    endo_fiber_angle = np.radians(60.0)  # +60° at endocardium\n",
    "    epi_fiber_angle = np.radians(-60.0)  # -60° at epicardium\n",
    "    \n",
    "    # Sheet angle parameters (in radians)\n",
    "    endo_sheet_angle = np.radians(-65.0)  # -65° at endocardium\n",
    "    epi_sheet_angle = np.radians(25.0)    # +25° at epicardium\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        # Normalize local coordinate system vectors\n",
    "        t_vec = TransmuralField[i] / np.linalg.norm(TransmuralField[i])\n",
    "        l_vec = LongitudinalField[i] / np.linalg.norm(LongitudinalField[i])\n",
    "        c_vec = CircumferentialField[i] / np.linalg.norm(CircumferentialField[i])\n",
    "        \n",
    "        # Interpolate fiber angle based on transmural position (linear interpolation)\n",
    "        phi = phi_transmural[i]\n",
    "        fiber_angle = endo_fiber_angle * (1 - phi) + epi_fiber_angle * phi\n",
    "        \n",
    "        # Interpolate sheet angle based on transmural position (linear interpolation)\n",
    "        sheet_angle = endo_sheet_angle * (1 - phi) + epi_sheet_angle * phi\n",
    "        \n",
    "        # Compute fiber direction by rotating the circumferential vector toward the longitudinal direction\n",
    "        # Rotation around transmural axis\n",
    "        fiber_dir = c_vec * np.cos(fiber_angle) + l_vec * np.sin(fiber_angle)\n",
    "        fiber_dir = fiber_dir / np.linalg.norm(fiber_dir)\n",
    "        \n",
    "        # IMPROVED SHEET CALCULATION:\n",
    "        # First, define sheet direction as a rotation of the transmural vector in the transmural-longitudinal plane\n",
    "        # This rotation is around an axis perpendicular to both transmural and longitudinal vectors (i.e., circumferential)\n",
    "        sheet_dir = t_vec * np.cos(sheet_angle) + l_vec * np.sin(sheet_angle)\n",
    "        \n",
    "        # Make sheet_dir orthogonal to fiber_dir using Gram-Schmidt process\n",
    "        # Project out any component of sheet_dir that's parallel to fiber_dir\n",
    "        fiber_component = np.dot(sheet_dir, fiber_dir) * fiber_dir\n",
    "        sheet_dir = sheet_dir - fiber_component\n",
    "        sheet_dir = sheet_dir / np.linalg.norm(sheet_dir)\n",
    "        \n",
    "        # Compute sheet normal as cross product to ensure perfect orthogonality\n",
    "        sheet_normal = np.cross(fiber_dir, sheet_dir)\n",
    "        sheet_normal = sheet_normal / np.linalg.norm(sheet_normal)\n",
    "        \n",
    "        # Store the results\n",
    "        fiber_directions[i] = fiber_dir\n",
    "        sheet_directions[i] = sheet_dir\n",
    "        sheet_normal_directions[i] = sheet_normal\n",
    "    \n",
    "    return fiber_directions, sheet_directions, sheet_normal_directions\n",
    "\n",
    "def verify_orthogonality(fiber_directions, sheet_directions, sheet_normal_directions):\n",
    "    \"\"\"\n",
    "    Verify that the fiber, sheet, and sheet normal directions form an orthogonal basis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fiber_directions : numpy.ndarray\n",
    "        Fiber direction vectors, shape (n_points, 3)\n",
    "    sheet_directions : numpy.ndarray\n",
    "        Sheet direction vectors, shape (n_points, 3)\n",
    "    sheet_normal_directions : numpy.ndarray\n",
    "        Sheet normal direction vectors, shape (n_points, 3)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (max_f_s_dot, max_f_n_dot, max_s_n_dot) maximum absolute dot products between vectors\n",
    "    \"\"\"\n",
    "    n_points = len(fiber_directions)\n",
    "    \n",
    "    max_f_s_dot = 0\n",
    "    max_f_n_dot = 0\n",
    "    max_s_n_dot = 0\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        f = fiber_directions[i]\n",
    "        s = sheet_directions[i]\n",
    "        n = sheet_normal_directions[i]\n",
    "        \n",
    "        # Compute dot products (should be close to 0 for orthogonal vectors)\n",
    "        f_s_dot = abs(np.dot(f, s))\n",
    "        f_n_dot = abs(np.dot(f, n))\n",
    "        s_n_dot = abs(np.dot(s, n))\n",
    "        \n",
    "        # Track maximum values\n",
    "        max_f_s_dot = max(max_f_s_dot, f_s_dot)\n",
    "        max_f_n_dot = max(max_f_n_dot, f_n_dot)\n",
    "        max_s_n_dot = max(max_s_n_dot, s_n_dot)\n",
    "    \n",
    "    return max_f_s_dot, max_f_n_dot, max_s_n_dot\n",
    "\n",
    "def validate_right_handed_system(fiber_directions, sheet_directions, sheet_normal_directions):\n",
    "    \"\"\"\n",
    "    Validate that the basis vectors form a right-handed orthonormal system.\n",
    "    \n",
    "    In a right-handed system, fiber × sheet = sheet_normal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fiber_directions : numpy.ndarray\n",
    "        Fiber direction vectors, shape (n_points, 3)\n",
    "    sheet_directions : numpy.ndarray\n",
    "        Sheet direction vectors, shape (n_points, 3)\n",
    "    sheet_normal_directions : numpy.ndarray\n",
    "        Sheet normal direction vectors, shape (n_points, 3)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Minimum dot product between computed cross product and sheet normal\n",
    "        (should be close to 1 for consistent right-handed systems)\n",
    "    \"\"\"\n",
    "    n_points = len(fiber_directions)\n",
    "    min_alignment = 1.0\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        f = fiber_directions[i]\n",
    "        s = sheet_directions[i]\n",
    "        n = sheet_normal_directions[i]\n",
    "        \n",
    "        # Compute cross product\n",
    "        expected_normal = np.cross(f, s)\n",
    "        expected_normal = expected_normal / np.linalg.norm(expected_normal)\n",
    "        \n",
    "        # Check alignment with provided normal (dot product should be close to 1)\n",
    "        alignment = np.dot(expected_normal, n)\n",
    "        min_alignment = min(min_alignment, alignment)\n",
    "    \n",
    "    return min_alignment\n",
    "\n",
    "# Example usage:\n",
    "fiber_dirs, sheet_dirs, sheet_normal_dirs = compute_fiber_sheet_directions(\n",
    "    TransmuralField, LongitudinalField, CircumferentialField, phi_transmural)\n",
    "\n",
    "# Verify orthogonality\n",
    "max_dots = verify_orthogonality(fiber_dirs, sheet_dirs, sheet_normal_dirs)\n",
    "print(f\"Maximum dot products: {max_dots}\")\n",
    "\n",
    "# Validate right-handed system\n",
    "min_alignment = validate_right_handed_system(fiber_dirs, sheet_dirs, sheet_normal_dirs)\n",
    "print(f\"Minimum right-hand system alignment: {min_alignment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original points: 110822\n",
      "Original triangles: 77128\n",
      "Epicardium triangles: 35848\n",
      "Endocardium triangles: 39581\n",
      "Sampled epicardium points: 361\n",
      "Sampled endocardium points: 399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfff4ded6f34d4bad4be90a8ce39ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:63147/index.html?ui=P_0x137d2e560_1&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "from pyvista import themes\n",
    "import os\n",
    "import random\n",
    "\n",
    "def visualize_fibers(points, triangles, triangle_regions, fiber_dirs, \n",
    "                    subsample_factor=20, glyph_scale=0.005):\n",
    "    \"\"\"\n",
    "    Create side-by-side visualizations of the fiber directions on epicardium and endocardium.\n",
    "    \n",
    "    Left plot: Endocardium (triangle_regions == 3 or 4) in red\n",
    "    Right plot: Epicardium (triangle_regions == 2) in blue\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : numpy.ndarray\n",
    "        Array of 3D coordinates of the mesh vertices\n",
    "    triangles : numpy.ndarray\n",
    "        Array of triangle indices (each row contains 3 indices)\n",
    "    triangle_regions : numpy.ndarray\n",
    "        Array indicating the region each triangle belongs to\n",
    "        (2 for epicardium, 3 or 4 for endocardium)\n",
    "    fiber_dirs : numpy.ndarray\n",
    "        Array of fiber direction vectors for each point\n",
    "    subsample_factor : int, optional\n",
    "        Factor by which to subsample points for vector visualization\n",
    "    glyph_scale : float, optional\n",
    "        Scale factor for the vector glyphs\n",
    "    \"\"\"\n",
    "    # Set up a nice theme for visualization\n",
    "    my_theme = themes.DarkTheme()\n",
    "    my_theme.lighting = True\n",
    "    my_theme.show_edges = False\n",
    "    my_theme.background = 'white'\n",
    "    my_theme.window_size = [1600, 800]\n",
    "    pv.set_plot_theme(my_theme)\n",
    "    \n",
    "    print(f\"Original points: {len(points)}\")\n",
    "    print(f\"Original triangles: {len(triangles)}\")\n",
    "    \n",
    "    # Prepare triangle cells for PyVista format\n",
    "    triangle_cells = np.column_stack(\n",
    "        (np.full(len(triangles), 3), triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    # Create full mesh\n",
    "    full_mesh = pv.PolyData(points, triangle_cells)\n",
    "    \n",
    "    # Create a plotter with two side-by-side viewports\n",
    "    plotter = pv.Plotter(shape=(1, 2))\n",
    "    \n",
    "    # Filter triangles by region\n",
    "    epicardium_triangles = triangles[np.logical_or(triangle_regions == 2, triangle_regions == -1)]\n",
    "    endocardium_triangles = triangles[np.logical_or(triangle_regions == 3, np.logical_or(triangle_regions == 4, triangle_regions == -1))]\n",
    "    \n",
    "    print(f\"Epicardium triangles: {len(epicardium_triangles)}\")\n",
    "    print(f\"Endocardium triangles: {len(endocardium_triangles)}\")\n",
    "    \n",
    "    # Create separate meshes for each surface\n",
    "    epicardium_cells = np.column_stack(\n",
    "        (np.full(len(epicardium_triangles), 3), epicardium_triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    endocardium_cells = np.column_stack(\n",
    "        (np.full(len(endocardium_triangles), 3), endocardium_triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    epicardium_mesh = pv.PolyData(points, epicardium_cells)\n",
    "    endocardium_mesh = pv.PolyData(points, endocardium_cells)\n",
    "    \n",
    "    # Function to sample points from a mesh\n",
    "    def create_sampled_vectors(mesh):\n",
    "        # Extract unique points from this mesh\n",
    "        unique_point_ids = np.unique(mesh.faces.reshape(-1, 4)[:, 1:].flatten())\n",
    "        \n",
    "        # Further sample to reduce number of arrows\n",
    "        n_sample = min(len(unique_point_ids), len(unique_point_ids) // subsample_factor)\n",
    "        sample_indices = sorted(random.sample(list(unique_point_ids), n_sample))\n",
    "        \n",
    "        # Create a point cloud with the sampled points\n",
    "        sampled_points = points[sample_indices]\n",
    "        point_cloud = pv.PolyData(sampled_points)\n",
    "        \n",
    "        # Add vector data\n",
    "        point_cloud[\"fibers\"] = fiber_dirs[sample_indices]\n",
    "        \n",
    "        return point_cloud, sample_indices\n",
    "    \n",
    "    # Create sampled vector fields for each surface\n",
    "    epicardium_vectors, epi_indices = create_sampled_vectors(epicardium_mesh)\n",
    "    endocardium_vectors, endo_indices = create_sampled_vectors(endocardium_mesh)\n",
    "    \n",
    "    print(f\"Sampled epicardium points: {epicardium_vectors.n_points}\")\n",
    "    print(f\"Sampled endocardium points: {endocardium_vectors.n_points}\")\n",
    "    \n",
    "    # Left viewport: Endocardium (in red)\n",
    "    plotter.subplot(0, 0)\n",
    "    plotter.add_text(\"Endocardium Fiber Directions\", font_size=16, color=\"black\")\n",
    "    \n",
    "    # Add endocardium surface\n",
    "    plotter.add_mesh(endocardium_mesh, color='mistyrose', opacity=0.8)\n",
    "    \n",
    "    # Add fiber directions for endocardium\n",
    "    fiber_arrows = endocardium_vectors.glyph(\n",
    "        orient=\"fibers\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(fiber_arrows, color=\"red\", label=\"Fiber Direction\")\n",
    "    \n",
    "    # Add legend\n",
    "    plotter.add_legend(size=(0.2, 0.2), loc='upper right')\n",
    "    \n",
    "    # Right viewport: Epicardium (in blue)\n",
    "    plotter.subplot(0, 1)\n",
    "    plotter.add_text(\"Epicardium Fiber Directions\", font_size=16, color=\"black\")\n",
    "    \n",
    "    # Add epicardium surface\n",
    "    plotter.add_mesh(epicardium_mesh, color='lightblue', opacity=0.8)\n",
    "    \n",
    "    # Add fiber directions for epicardium\n",
    "    fiber_arrows = epicardium_vectors.glyph(\n",
    "        orient=\"fibers\",\n",
    "        scale=False,\n",
    "        factor=glyph_scale\n",
    "    )\n",
    "    plotter.add_mesh(fiber_arrows, color=\"blue\", label=\"Fiber Direction\")\n",
    "    \n",
    "    # Add legend\n",
    "    plotter.add_legend(size=(0.2, 0.2), loc='upper right')\n",
    "    \n",
    "    # Link the cameras between the two viewports\n",
    "    plotter.link_views()\n",
    "    \n",
    "    # Set camera position\n",
    "    plotter.camera_position = 'xz'\n",
    "    plotter.camera.zoom(1.2)\n",
    "    \n",
    "    # Show the plot\n",
    "    plotter.show()\n",
    "\n",
    "    plotter.screenshot('../figures/fiber_directions.png')    \n",
    "\n",
    "visualize_fibers(\n",
    "    points, triangles, triangle_regions,\n",
    "    fiber_dirs, subsample_factor=50, glyph_scale=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 260386 elements for .lon file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing element directions:   0%|          | 0/260386 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing element directions: 100%|██████████| 260386/260386 [00:04<00:00, 60437.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying orthogonality of element directions...\n",
      "Maximum dot products: fiber·sheet=0.999433, fiber·normal=0.999891, sheet·normal=0.998845\n",
      "Writing to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.lon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing .lon file: 100%|██████████| 27/27 [00:00<00:00, 46.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote fiber orientations to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.lon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "def average_unit_vector(vectors):\n",
    "    \"\"\"\n",
    "    Calculate the average unit vector from a set of vectors.\n",
    "    \"\"\"\n",
    "    average_vector = np.mean(vectors, axis=0)\n",
    "    norm = np.linalg.norm(average_vector)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if norm < 1e-10:\n",
    "        return np.array([1.0, 0.0, 0.0])  # Default to x-axis if vectors cancel out\n",
    "    \n",
    "    return average_vector / norm\n",
    "\n",
    "def precompute_element_directions(fiber_dirs, sheet_dirs, sheet_normal_dirs, tetrahedra):\n",
    "    \"\"\"\n",
    "    Precompute the averaged fiber, sheet and sheet normal directions for all elements\n",
    "    \"\"\"\n",
    "    n_elements = len(tetrahedra)\n",
    "    element_fiber_dirs = np.zeros((n_elements, 3))\n",
    "    element_sheet_dirs = np.zeros((n_elements, 3))\n",
    "    element_normal_dirs = np.zeros((n_elements, 3))\n",
    "    \n",
    "    # Use vectorized operations where possible\n",
    "    for i in tqdm(range(n_elements), desc=\"Precomputing element directions\"):\n",
    "        # Get the nodes for this element\n",
    "        tet_nodes = tetrahedra[i]\n",
    "        \n",
    "        # Average the directions for this element\n",
    "        element_fiber_dirs[i] = average_unit_vector(fiber_dirs[tet_nodes])\n",
    "        element_sheet_dirs[i] = average_unit_vector(sheet_dirs[tet_nodes])\n",
    "        element_normal_dirs[i] = average_unit_vector(sheet_normal_dirs[tet_nodes])\n",
    "    \n",
    "    return element_fiber_dirs, element_sheet_dirs, element_normal_dirs\n",
    "\n",
    "def write_lon_file(filename, fiber_directions, sheet_directions, sheet_normal_directions, tetrahedra, batch_size=10000):\n",
    "    \"\"\"\n",
    "    Write fiber, sheet, and sheet normal directions to a .lon file for openCARP.\n",
    "    \"\"\"\n",
    "    n_elements = len(tetrahedra)\n",
    "    \n",
    "    print(f\"Processing {n_elements} elements for .lon file...\")\n",
    "    \n",
    "    # Precompute all element directions at once\n",
    "    element_fiber_dirs, element_sheet_dirs, element_normal_dirs = precompute_element_directions(\n",
    "        fiber_directions, sheet_directions, sheet_normal_directions, tetrahedra\n",
    "    )\n",
    "    \n",
    "    # Verify orthogonality of precomputed directions\n",
    "    print(\"Verifying orthogonality of element directions...\")\n",
    "    max_dot_f_s = np.max(np.abs(np.sum(element_fiber_dirs * element_sheet_dirs, axis=1)))\n",
    "    max_dot_f_n = np.max(np.abs(np.sum(element_fiber_dirs * element_normal_dirs, axis=1)))\n",
    "    max_dot_s_n = np.max(np.abs(np.sum(element_sheet_dirs * element_normal_dirs, axis=1)))\n",
    "    \n",
    "    print(f\"Maximum dot products: fiber·sheet={max_dot_f_s:.6f}, fiber·normal={max_dot_f_n:.6f}, sheet·normal={max_dot_s_n:.6f}\")\n",
    "    \n",
    "    print(f\"Writing to {filename}...\")\n",
    "    \n",
    "    # Write to file in batches\n",
    "    with open(filename, 'w') as f:\n",
    "        # Header: 3 for fiber, sheet, and sheet-normal directions\n",
    "        f.write('2\\n')\n",
    "        \n",
    "        # Write in batches to avoid memory issues\n",
    "        for i in tqdm(range(0, n_elements, batch_size), desc=\"Writing .lon file\"):\n",
    "            batch_end = min(i + batch_size, n_elements)\n",
    "            batch_elements = range(i, batch_end)\n",
    "            \n",
    "            # Create a single string for the batch\n",
    "            lines = []\n",
    "            for j in batch_elements:\n",
    "                f_vec = element_fiber_dirs[j]\n",
    "                s_vec = element_sheet_dirs[j]\n",
    "                line = f\"{f_vec[0]:.8f} {f_vec[1]:.8f} {f_vec[2]:.8f} \" + \\\n",
    "                       f\"{s_vec[0]:.8f} {s_vec[1]:.8f} {s_vec[2]:.8f} \"\n",
    "                lines.append(line)\n",
    "            \n",
    "            # Write the batch\n",
    "            f.write('\\n'.join(lines) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully wrote fiber orientations to {filename}\")\n",
    "\n",
    "write_lon_file(\n",
    "    f\"{data_path}{output_prefix}.lon\", \n",
    "    fiber_dirs, \n",
    "    sheet_dirs, \n",
    "    sheet_normal_dirs,  # Now including sheet normal directions\n",
    "    tetrahedra\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying points with phi_longitudinal between 0.1 and 0.9...\n",
      "Found 45296 points with valid longitudinal coordinate\n",
      "Identifying endocardial points...\n",
      "Found 11843 points on the endocardium\n",
      "Found 9917 points that satisfy both criteria\n",
      "Tagging tetrahedra...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 148.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged 72064 tetrahedra (27.68%) as fast conducting endocardium\n",
      "Writing modified element file to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.elem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260386/260386 [00:00<00:00, 816211.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote modified element file to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.elem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def tag_fast_conducting_endocardium(\n",
    "    points, \n",
    "    tetrahedra, \n",
    "    triangles, \n",
    "    triangle_regions, \n",
    "    phi_longitudinal, \n",
    "    output_file\n",
    "):\n",
    "    \"\"\"\n",
    "    Tag tetrahedra for fast conducting endocardium based on:\n",
    "    1. Points with phi_longitudinal between 0.1 and 0.9\n",
    "    2. Points that are part of triangles with triangle_regions == 3 or 4\n",
    "    \"\"\"\n",
    "    # Step 1: Identify points that satisfy phi_longitudinal criterion\n",
    "    print(\"Identifying points with phi_longitudinal between 0.1 and 0.9...\")\n",
    "    longitudinal_mask = (phi_longitudinal >= 0.1) & (phi_longitudinal <= 0.9)\n",
    "    valid_longitudinal_points = set(np.where(longitudinal_mask)[0])\n",
    "    print(f\"Found {len(valid_longitudinal_points)} points with valid longitudinal coordinate\")\n",
    "    \n",
    "    # Step 2: Identify points that are part of endocardial triangles (regions 3 or 4)\n",
    "    print(\"Identifying endocardial points...\")\n",
    "    endocardial_triangles = np.where((triangle_regions == 3) | (triangle_regions == 4))[0]\n",
    "    endocardial_points = set()\n",
    "    \n",
    "    for tri_idx in endocardial_triangles:\n",
    "        for point_idx in triangles[tri_idx]:\n",
    "            endocardial_points.add(point_idx)\n",
    "    \n",
    "    print(f\"Found {len(endocardial_points)} points on the endocardium\")\n",
    "    \n",
    "    # Step 3: Find intersection of both sets\n",
    "    valid_points = valid_longitudinal_points.intersection(endocardial_points)\n",
    "    print(f\"Found {len(valid_points)} points that satisfy both criteria\")\n",
    "    \n",
    "    # Step 4: Mark tetrahedra containing valid points\n",
    "    print(\"Tagging tetrahedra...\")\n",
    "    n_tetrahedra = tetrahedra.shape[0]\n",
    "    tetrahedra_tags = np.zeros(n_tetrahedra, dtype=int)\n",
    "    \n",
    "    # Convert to set for faster lookups\n",
    "    valid_points_set = set(valid_points)\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    batch_size = 10000\n",
    "    for batch_start in tqdm(range(0, n_tetrahedra, batch_size)):\n",
    "        batch_end = min(batch_start + batch_size, n_tetrahedra)\n",
    "        batch_tetrahedra = tetrahedra[batch_start:batch_end]\n",
    "        \n",
    "        # Check each tetrahedron in the batch\n",
    "        for i, tet in enumerate(batch_tetrahedra):\n",
    "            # If any point in the tetrahedron is valid, tag it as 1\n",
    "            if any(point_idx in valid_points_set for point_idx in tet):\n",
    "                tetrahedra_tags[batch_start + i] = 1\n",
    "    \n",
    "    num_tagged = np.sum(tetrahedra_tags == 1)\n",
    "    print(f\"Tagged {num_tagged} tetrahedra ({(num_tagged/n_tetrahedra)*100:.2f}%) as fast conducting endocardium\")\n",
    "    \n",
    "    # Step 5: Write the modified .elem file\n",
    "    print(f\"Writing modified element file to {output_file}...\")\n",
    "    with open(output_file, 'w') as fout:\n",
    "        # Write header (number of tetrahedra)\n",
    "        fout.write(f\"{n_tetrahedra}\\n\")\n",
    "        \n",
    "        # Process each tetrahedron and write to file\n",
    "        for i in tqdm(range(n_tetrahedra)):\n",
    "            tet = tetrahedra[i]\n",
    "            # Format: Tt node1 node2 node3 node4 tag\n",
    "            line = f\"Tt {tet[0]} {tet[1]} {tet[2]} {tet[3]} {tetrahedra_tags[i]}\"\n",
    "            fout.write(f\"{line}\\n\")\n",
    "    \n",
    "    print(f\"Successfully wrote modified element file to {output_file}\")\n",
    "\n",
    "tag_fast_conducting_endocardium(\n",
    "    points, \n",
    "    tetrahedra, \n",
    "    triangles, \n",
    "    triangle_regions, \n",
    "    phi_longitudinal, \n",
    "    f\"{data_path}{output_prefix}.elem\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fascicular sites: 10\n",
      "Cluster 0: 4 points, Cluster 1: 6 points\n",
      "Selected LV cluster (label 1) with 6 points\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "def filter_fascicular_sites_closer_to_LV(points, is_fascicular_site, septal_normal, LV_center, RV_center):\n",
    "    \"\"\"\n",
    "    Filter fascicular sites to keep only those closer to the left ventricle.\n",
    "    \"\"\"\n",
    "    # Get indices and coordinates of all fascicular sites\n",
    "    fascicular_indices = np.where(is_fascicular_site)[0]\n",
    "    fascicular_points = points[fascicular_indices]\n",
    "    \n",
    "    print(f\"Total fascicular sites: {len(fascicular_indices)}\")\n",
    "    \n",
    "    if len(fascicular_indices) == 0:\n",
    "        print(\"No fascicular sites found.\")\n",
    "        return is_fascicular_site\n",
    "    \n",
    "    # If there's only one cluster, check if it's closer to LV or RV\n",
    "    if len(fascicular_indices) < 5:  # Not enough points for reliable clustering\n",
    "        # Compute signed distance to the plane separating LV and RV\n",
    "        # The plane passes through the middle point between LV and RV centers\n",
    "        # with septal_normal as its normal\n",
    "        mid_point = (LV_center + RV_center) / 2\n",
    "        \n",
    "        # For each fascicular point, calculate its position relative to the plane\n",
    "        # Positive values mean the point is on the LV side\n",
    "        distances = np.dot(fascicular_points - mid_point, septal_normal)\n",
    "        \n",
    "        if np.all(distances > 0) or np.all(distances < 0):\n",
    "            # All points are on the same side\n",
    "            is_lv_side = np.mean(distances) > 0\n",
    "            print(f\"All fascicular sites are on the {'LV' if is_lv_side else 'RV'} side.\")\n",
    "            if not is_lv_side:\n",
    "                # If all points are on RV side, return empty array\n",
    "                return np.zeros_like(is_fascicular_site, dtype=bool)\n",
    "            return is_fascicular_site\n",
    "        \n",
    "    # Use k-means clustering to separate the two disks\n",
    "    centroids, labels = kmeans2(fascicular_points, k=2, minit='points')\n",
    "    \n",
    "    # Determine which centroid is closer to LV\n",
    "    # Calculate vectors from RV center to each centroid\n",
    "    vectors_to_centroids = centroids - RV_center\n",
    "    \n",
    "    # Project these vectors onto the septal normal\n",
    "    projections = np.dot(vectors_to_centroids, septal_normal)\n",
    "    \n",
    "    # The centroid with larger projection is closer to LV\n",
    "    lv_cluster_label = np.argmax(projections)\n",
    "    \n",
    "    # Count points in each cluster\n",
    "    cluster0_count = np.sum(labels == 0)\n",
    "    cluster1_count = np.sum(labels == 1)\n",
    "    print(f\"Cluster 0: {cluster0_count} points, Cluster 1: {cluster1_count} points\")\n",
    "    print(f\"Selected LV cluster (label {lv_cluster_label}) with {np.sum(labels == lv_cluster_label)} points\")\n",
    "    \n",
    "    # Create a new boolean array with only the LV cluster points\n",
    "    is_lv_fascicular_site = np.zeros_like(is_fascicular_site, dtype=bool)\n",
    "    lv_indices = fascicular_indices[labels == lv_cluster_label]\n",
    "    is_lv_fascicular_site[lv_indices] = True\n",
    "    \n",
    "    return is_lv_fascicular_site\n",
    "\n",
    "disk_height_tolerance = 0.05\n",
    "disk_radius = 0.02\n",
    "\n",
    "coord_t = 0.65\n",
    "coord_l = 0.30\n",
    "coord_c = 0.8\n",
    "\n",
    "is_fascicular_site = np.logical_and( np.abs(phi_transmural - coord_t) < disk_height_tolerance , ((phi_longitudinal - coord_l)**2.0 + (phi_circumferential - coord_c)**2.0) < disk_radius**2.0 ) \n",
    "\n",
    "LV_points = np.array(list(set(triangles[triangle_regions == 3].flatten()))) # Left ventricular endocardium\n",
    "RV_points = np.array(list(set(triangles[triangle_regions == 4].flatten()))) # Right ventricular endocardium\n",
    "\n",
    "LV_center = points[LV_points].mean(axis=0)\n",
    "RV_center = points[RV_points].mean(axis=0)\n",
    "\n",
    "septal_normal = RV_center - LV_center\n",
    "septal_normal /= np.linalg.norm(septal_normal)\n",
    "\n",
    "is_fascicular_site = filter_fascicular_sites_closer_to_LV(points, is_fascicular_site, septal_normal, LV_center, RV_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original points: 110822\n",
      "Original triangles: 77128\n",
      "Number of fascicular sites: 6\n",
      "Endocardium triangles: 39581\n",
      "Displaying all 6 fascicular sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesmcgreivy/miniconda3/envs/openCARP/lib/python3.10/site-packages/pyvista/core/filters/data_set.py:2386: UserWarning: No vector-like data to use for orient. orient will be set to False.\n",
      "  warnings.warn(\"No vector-like data to use for orient. orient will be set to False.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bda2064c994723b4e4a1522f1adc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:63147/index.html?ui=P_0x3222ea0b0_13&reconnect=auto\" class=\"pyvist…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pyvista.plotting.plotter.Plotter at 0x3222ea0b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from pyvista import themes\n",
    "import os\n",
    "import random\n",
    "\n",
    "def visualize_fascicular_sites(points, triangles, triangle_regions, is_fascicular_site, \n",
    "                               sphere_scale=0.005):\n",
    "    \"\"\"\n",
    "    Visualize fascicular sites on the endocardial surface.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : numpy.ndarray\n",
    "        Array of 3D coordinates of the mesh vertices\n",
    "    triangles : numpy.ndarray\n",
    "        Array of triangle indices (each row contains 3 indices)\n",
    "    triangle_regions : numpy.ndarray\n",
    "        Array indicating the region each triangle belongs to\n",
    "        (2 for epicardium, 3 or 4 for endocardium)\n",
    "    is_fascicular_site : numpy.ndarray\n",
    "        Boolean array indicating whether each point is a fascicular site\n",
    "    subsample_factor : int, optional\n",
    "        Factor by which to subsample points for visualization\n",
    "    sphere_scale : float, optional\n",
    "        Scale factor for the spheres representing fascicular sites\n",
    "    \"\"\"\n",
    "    # Set up a nice theme for visualization\n",
    "    my_theme = themes.DarkTheme()\n",
    "    my_theme.lighting = True\n",
    "    my_theme.show_edges = False\n",
    "    my_theme.background = 'white'\n",
    "    my_theme.window_size = [1000, 800]\n",
    "    pv.set_plot_theme(my_theme)\n",
    "    \n",
    "    print(f\"Original points: {len(points)}\")\n",
    "    print(f\"Original triangles: {len(triangles)}\")\n",
    "    print(f\"Number of fascicular sites: {np.sum(is_fascicular_site)}\")\n",
    "    \n",
    "    # Filter triangles to get only endocardium\n",
    "    endocardium_triangles = triangles[np.logical_or(triangle_regions == 3, triangle_regions == 4)]\n",
    "    print(f\"Endocardium triangles: {len(endocardium_triangles)}\")\n",
    "    \n",
    "    # Create endocardium mesh\n",
    "    endocardium_cells = np.column_stack(\n",
    "        (np.full(len(endocardium_triangles), 3), endocardium_triangles)\n",
    "    ).flatten()\n",
    "    \n",
    "    endocardium_mesh = pv.PolyData(points, endocardium_cells)\n",
    "    \n",
    "    # Get indices of fascicular sites - use ALL of them, no subsampling\n",
    "    fascicular_indices = np.where(is_fascicular_site)[0]\n",
    "    print(f\"Displaying all {len(fascicular_indices)} fascicular sites\")\n",
    "    \n",
    "    # Create a new point cloud for fascicular sites\n",
    "    fascicular_points = points[fascicular_indices]\n",
    "    fascicular_cloud = pv.PolyData(fascicular_points)\n",
    "    \n",
    "    # Create a plotter\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_text(\"Endocardium with Fascicular Sites\", font_size=16, color=\"black\")\n",
    "    \n",
    "    # Add endocardium surface\n",
    "    plotter.add_mesh(endocardium_mesh, color='mistyrose', opacity=0.7, \n",
    "                     label=\"Endocardial Surface\")\n",
    "    \n",
    "    # Add spheres for fascicular sites\n",
    "    # Use glyph to create spheres at fascicular sites\n",
    "    spheres = fascicular_cloud.glyph(\n",
    "        geom=pv.Sphere(radius=1),\n",
    "        scale=False,\n",
    "        factor=sphere_scale\n",
    "    )\n",
    "    plotter.add_mesh(spheres, color=\"red\", label=\"Fascicular Sites\")\n",
    "    \n",
    "    # Add legend\n",
    "    plotter.add_legend(size=(0.2, 0.2), loc='upper right')\n",
    "    \n",
    "    # Set camera position for a good view\n",
    "    plotter.camera_position = 'xz'\n",
    "    plotter.camera.zoom(1.2)\n",
    "\n",
    "    # Show the plot\n",
    "    plotter.show()\n",
    "\n",
    "    plotter.screenshot('../figures/fascicular_sites.png') \n",
    "    \n",
    "    return plotter\n",
    "\n",
    "# Example usage:\n",
    "visualize_fascicular_sites(\n",
    "    points, triangles, triangle_regions,\n",
    "    is_fascicular_site, sphere_scale=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 6 fascicular site indices to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/fascicular_stim.vtx\n",
      "Successfully saved fascicular sites to /Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/fascicular_stim.vtx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/fascicular_stim.vtx'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_fascicular_sites_to_vtx(is_fascicular_site, output_filename):\n",
    "    \"\"\"\n",
    "    Save the indices of fascicular sites to a .vtx file.\n",
    "    \"\"\"\n",
    "    # Get indices of fascicular sites\n",
    "    site_indices = np.where(is_fascicular_site)[0]\n",
    "    num_sites = len(site_indices)\n",
    "    \n",
    "    print(f\"Saving {num_sites} fascicular site indices to {output_filename}\")\n",
    "    \n",
    "    # Write to file\n",
    "    with open(output_filename, 'w') as f:\n",
    "        # Write header (number of sites)\n",
    "        f.write(f\"{num_sites}\\n\")\n",
    "        f.write(\"extra\\n\")\n",
    "        \n",
    "        # Write each index on a new line\n",
    "        for idx in site_indices:\n",
    "            f.write(f\"{idx}\\n\")\n",
    "    \n",
    "    print(f\"Successfully saved fascicular sites to {os.path.abspath(output_filename)}\")\n",
    "    return os.path.abspath(output_filename)\n",
    "\n",
    "# Save to file:\n",
    "save_fascicular_sites_to_vtx(is_fascicular_site, output_filename=f\"{data_path}fascicular_stim.vtx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original points: 110822\n",
      "Subsampling points from 110822 to 50000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22716295d6c4af1af9f5f5307c78e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:63147/index.html?ui=P_0x3105337f0_10&reconnect=auto\" class=\"pyvist…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import random\n",
    "\n",
    "def visualize_phi(points, phi, subsample_factor=10, point_size=5, cmap=\"viridis\"):\n",
    "    \"\"\"\n",
    "    Visualize a scalar field using just points (no mesh connectivity required).\n",
    "    \"\"\"\n",
    "    # Set up theme\n",
    "    pv.set_plot_theme(\"document\")\n",
    "    \n",
    "    print(f\"Original points: {len(points)}\")\n",
    "    \n",
    "    # Subsample points to make visualization manageable\n",
    "    n_points = len(points)\n",
    "    n_sample = n_points // subsample_factor\n",
    "    \n",
    "    # Make sure we don't have too few or too many points\n",
    "    n_sample = max(1000, min(n_sample, 50000))\n",
    "    \n",
    "    print(f\"Subsampling points from {n_points} to {n_sample}\")\n",
    "    \n",
    "    # Random sampling\n",
    "    sample_indices = sorted(random.sample(range(n_points), n_sample))\n",
    "    \n",
    "    # Create subsampled arrays\n",
    "    sampled_points = points[sample_indices]\n",
    "    sampled_phi = phi[sample_indices]\n",
    "    \n",
    "    # Create point cloud\n",
    "    cloud = pv.PolyData(sampled_points)\n",
    "    cloud.point_data[\"transmural\"] = sampled_phi\n",
    "    \n",
    "    # Create plotter\n",
    "    plotter = pv.Plotter()\n",
    "    plotter.add_text(\"Phi Point Cloud\", font_size=14)\n",
    "    \n",
    "    # Add point cloud with scalar values\n",
    "    plotter.add_mesh(cloud, render_points_as_spheres=True, point_size=point_size,\n",
    "                    scalars=\"transmural\", cmap=cmap, opacity=1.0,\n",
    "                    show_scalar_bar=True, scalar_bar_args={\"title\": \"Phi\"})\n",
    "    \n",
    "    # Set view and show\n",
    "    plotter.view_isometric()\n",
    "    plotter.show()\n",
    "\n",
    "visualize_phi(points, phi_longitudinal, subsample_factor=1, point_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_fiber_directions(lon_file_path):\n",
    "    \"\"\"\n",
    "    Read fiber directions from a .lon file\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lon_file_path : str\n",
    "        Path to the .lon file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Array of shape (n_elements, 3) containing the fiber directions\n",
    "    \"\"\"\n",
    "    # Open the file and read all lines\n",
    "    with open(lon_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Skip the first line (header)\n",
    "    data_lines = lines[1:]\n",
    "    \n",
    "    # Initialize an array to store fiber directions\n",
    "    n_elements = len(data_lines)\n",
    "    fiber_directions = np.zeros((n_elements, 3))\n",
    "    \n",
    "    # Parse each line to extract the fiber directions\n",
    "    for i, line in enumerate(data_lines):\n",
    "        # Split the line into values\n",
    "        values = line.strip().split()\n",
    "        \n",
    "        # First 3 values are the fiber direction\n",
    "        fiber_directions[i, 0] = float(values[0])\n",
    "        fiber_directions[i, 1] = float(values[1])\n",
    "        fiber_directions[i, 2] = float(values[2])\n",
    "    \n",
    "    return fiber_directions\n",
    "\n",
    "def map_element_fibers_to_points(element_fiber_dirs, tetrahedra, n_points):\n",
    "    \"\"\"\n",
    "    Map element fiber directions to mesh points using a vectorized approach\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    element_fiber_dirs : numpy.ndarray\n",
    "        Array of shape (n_elements, 3) containing fiber directions for each element\n",
    "    tetrahedra : numpy.ndarray\n",
    "        Array of shape (n_elements, 4) containing point indices for each tetrahedron\n",
    "    n_points : int\n",
    "        Total number of points in the mesh\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Array of shape (n_points, 3) containing averaged fiber directions for each point\n",
    "    \"\"\"\n",
    "    # Initialize arrays to store sum of fiber directions and count of elements per point\n",
    "    fiber_sum = np.zeros((n_points, 3))\n",
    "    count = np.zeros(n_points)\n",
    "    \n",
    "    # Create a flattened index of point-element pairs\n",
    "    elem_indices = np.repeat(np.arange(len(tetrahedra)), 4)\n",
    "    point_indices = tetrahedra.flatten()\n",
    "    \n",
    "    # Add the fiber direction of each element to its associated points\n",
    "    for i, p_idx in enumerate(point_indices):\n",
    "        elem_idx = elem_indices[i]\n",
    "        fiber_sum[p_idx] += element_fiber_dirs[elem_idx]\n",
    "        count[p_idx] += 1\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    count[count == 0] = 1\n",
    "    \n",
    "    # Compute average fiber direction for each point\n",
    "    fiber_dirs = fiber_sum / count[:, np.newaxis]\n",
    "    \n",
    "    # Normalize the fiber directions\n",
    "    norms = np.linalg.norm(fiber_dirs, axis=1)\n",
    "    norms[norms == 0] = 1  # Avoid division by zero\n",
    "    fiber_dirs = fiber_dirs / norms[:, np.newaxis]\n",
    "    \n",
    "    return fiber_dirs\n",
    "\n",
    "# Usage example\n",
    "lon_file_path = \"/Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001_lowres/heart_instance_001_lowres.lon\"\n",
    "element_fiber_dirs = read_fiber_directions(lon_file_path)\n",
    "\n",
    "# Assuming points and tetrahedra are already defined\n",
    "n_points = len(points)\n",
    "fiber_dirs = map_element_fibers_to_points(element_fiber_dirs, tetrahedra, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vtk.util import numpy_support\n",
    "import os\n",
    "\n",
    "# Function to read VTP files\n",
    "def read_vtp(filename):\n",
    "    reader = vtk.vtkXMLPolyDataReader()\n",
    "    reader.SetFileName(filename)\n",
    "    reader.Update()\n",
    "    polydata = reader.GetOutput()\n",
    "    return polydata\n",
    "\n",
    "# Function to read VTU files\n",
    "def read_vtu(filename):\n",
    "    reader = vtk.vtkXMLUnstructuredGridReader()\n",
    "    reader.SetFileName(filename)\n",
    "    reader.Update()\n",
    "    grid = reader.GetOutput()\n",
    "    return grid\n",
    "\n",
    "# Function to extract and save Universal Ventricular Coordinates (UVC)\n",
    "def extract_save_uvc(volume_mesh, output_prefix, output_path):\n",
    "    # UVC coordinate names to extract\n",
    "    uvc_names = [\"tv\", \"tm\", \"rtSin\", \"rtCos\", \"rt\", \"ab\"]\n",
    "    \n",
    "    # Dictionary to store the coordinates\n",
    "    coordinates = {}\n",
    "    \n",
    "    # Extract each coordinate if available\n",
    "    for coord_name in uvc_names:\n",
    "        if volume_mesh.GetPointData().HasArray(coord_name):\n",
    "            data_array = volume_mesh.GetPointData().GetArray(coord_name)\n",
    "            coordinates[coord_name] = numpy_support.vtk_to_numpy(data_array)\n",
    "            print(f\"Extracted {coord_name} shape: {coordinates[coord_name].shape}\")\n",
    "            print(f\"{coord_name} range: {coordinates[coord_name].min()} to {coordinates[coord_name].max()}\")\n",
    "    \n",
    "    # Create a pandas DataFrame from the coordinates\n",
    "    if coordinates:\n",
    "        df = pd.DataFrame(coordinates)\n",
    "        # Create full path for outputs\n",
    "        csv_path = os.path.join(output_path, f\"UVC_{output_prefix}.csv\")\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved UVC data to {csv_path}\")\n",
    "    else:\n",
    "        print(\"No UVC data found in the volume mesh\")\n",
    "\n",
    "# Function to convert VTK data to openCARP format\n",
    "def convert_to_opencarp(volume_mesh, surface_mesh, output_prefix, output_path):\n",
    "    # Extract and save UVC data\n",
    "    extract_save_uvc(volume_mesh, output_prefix, output_path)\n",
    "    \n",
    "    # Generate full paths for output files\n",
    "    pts_path = os.path.join(output_path, f\"{output_prefix}.pts\")\n",
    "    elem_path = os.path.join(output_path, f\"{output_prefix}.elem\")\n",
    "    surf_path = os.path.join(output_path, f\"{output_prefix}.surf\")\n",
    "    \n",
    "    # Generate .pts file from volume mesh points\n",
    "    points = volume_mesh.GetPoints()\n",
    "    num_points = points.GetNumberOfPoints()\n",
    "    \n",
    "    with open(pts_path, \"w\") as pts_file:\n",
    "        pts_file.write(f\"{num_points}\\n\")\n",
    "        for i in range(num_points):\n",
    "            point = points.GetPoint(i)\n",
    "            pts_file.write(f\"{point[0]} {point[1]} {point[2]}\\n\")\n",
    "    \n",
    "    print(f\"Created {pts_path} with {num_points} points\")\n",
    "    \n",
    "    # Generate .elem file from volume mesh cells (tetrahedra)\n",
    "    num_cells = volume_mesh.GetNumberOfCells()\n",
    "    \n",
    "    with open(elem_path, \"w\") as elem_file:\n",
    "        elem_file.write(f\"{num_cells}\\n\")\n",
    "        \n",
    "        # Determine if we have cell data for regions\n",
    "        cell_data = None\n",
    "        region_id_array_name = None\n",
    "        \n",
    "        for i in range(volume_mesh.GetCellData().GetNumberOfArrays()):\n",
    "            array_name = volume_mesh.GetCellData().GetArrayName(i)\n",
    "            # Possible names for region IDs in the cell data\n",
    "            if array_name in [\"region\", \"material\", \"celldata\"]:\n",
    "                region_id_array_name = array_name\n",
    "                cell_data = numpy_support.vtk_to_numpy(volume_mesh.GetCellData().GetArray(array_name))\n",
    "                break\n",
    "        \n",
    "        # Default region ID if no cell data is available\n",
    "        default_region_id = 0\n",
    "        \n",
    "        for i in range(num_cells):\n",
    "            cell = volume_mesh.GetCell(i)\n",
    "            \n",
    "            # Check if the cell is a tetrahedron (VTK_TETRA = 10)\n",
    "            if cell.GetCellType() == 10:  # VTK_TETRA\n",
    "                # Get the 4 point IDs of the tetrahedron\n",
    "                point_ids = [cell.GetPointId(j) for j in range(4)]\n",
    "                \n",
    "                # Get region ID for this cell if available\n",
    "                region_id = default_region_id\n",
    "                if cell_data is not None:\n",
    "                    region_id = int(cell_data[i])\n",
    "                \n",
    "                # Write in Tt format for tetrahedron with region ID\n",
    "                # Note: openCARP is 0-indexed, same as VTK\n",
    "                elem_file.write(f\"Tt {point_ids[0]} {point_ids[1]} {point_ids[2]} {point_ids[3]} {region_id}\\n\")\n",
    "            else:\n",
    "                print(f\"Warning: Ignoring non-tetrahedral cell (type {cell.GetCellType()}) at index {i}\")\n",
    "    \n",
    "    print(f\"Created {output_prefix}.elem with tetrahedral elements\")\n",
    "    \n",
    "    # Generate .surf file from surface mesh triangles\n",
    "    # Extract class/region information if available\n",
    "    region_labels = None\n",
    "    if surface_mesh.GetPointData().HasArray(\"class\"):\n",
    "        class_array = surface_mesh.GetPointData().GetArray(\"class\")\n",
    "        region_labels = numpy_support.vtk_to_numpy(class_array)\n",
    "    \n",
    "    # Create a dictionary to organize triangles by region\n",
    "    triangles_by_region = {}\n",
    "    \n",
    "    num_surface_cells = surface_mesh.GetNumberOfCells()\n",
    "    for i in range(num_surface_cells):\n",
    "        cell = surface_mesh.GetCell(i)\n",
    "        \n",
    "        # Check if the cell is a triangle (VTK_TRIANGLE = 5)\n",
    "        if cell.GetCellType() == 5:  # VTK_TRIANGLE\n",
    "            # Get the 3 point IDs of the triangle\n",
    "            point_ids = [cell.GetPointId(j) for j in range(3)]\n",
    "            \n",
    "            # Determine region for this triangle\n",
    "            # We need to map the surface point IDs to volume point IDs\n",
    "            # For simplicity, we'll use the most common region among the triangle's points\n",
    "            region = 0  # Default region\n",
    "            \n",
    "            if region_labels is not None:\n",
    "                # Get the region labels for the points in this triangle\n",
    "                triangle_regions = [region_labels[point_id] for point_id in point_ids]\n",
    "                \n",
    "                # Use the most common region label for this triangle\n",
    "                from collections import Counter\n",
    "                region = Counter(triangle_regions).most_common(1)[0][0]\n",
    "            \n",
    "            # Add this triangle to the appropriate region\n",
    "            if region not in triangles_by_region:\n",
    "                triangles_by_region[region] = []\n",
    "            \n",
    "            triangles_by_region[region].append(point_ids)\n",
    "    \n",
    "    # Write the .surf file with triangles organized by region\n",
    "    with open(surf_path, \"w\") as surf_file:\n",
    "        # For each region, write the number of triangles in that region followed by Reg ID\n",
    "        for region, triangles in sorted(triangles_by_region.items()):\n",
    "            num_triangles_in_region = len(triangles)\n",
    "            surf_file.write(f\"{num_triangles_in_region} Reg {region}\\n\")\n",
    "            \n",
    "            # Write all triangles for this region\n",
    "            for point_ids in triangles:\n",
    "                surf_file.write(f\"Tr {point_ids[0]} {point_ids[1]} {point_ids[2]}\\n\")\n",
    "    \n",
    "    print(f\"Created {output_prefix}.surf with surface triangles\")\n",
    "\n",
    "# Main function to read VTK files and convert to openCARP format\n",
    "def vtk_to_opencarp(vtp_filename, vtu_filename, output_prefix, output_path):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"Reading surface mesh: {vtp_filename}\")\n",
    "    surface_mesh = read_vtp(vtp_filename)\n",
    "    \n",
    "    print(f\"Reading volume mesh: {vtu_filename}\")\n",
    "    volume_mesh = read_vtu(vtu_filename)\n",
    "    \n",
    "    print(f\"Converting to openCARP format. Output directory: {output_path}\")\n",
    "    convert_to_opencarp(volume_mesh, surface_mesh, output_prefix, output_path)\n",
    "    \n",
    "    print(f\"Conversion complete! Files saved to: {output_path}\")\n",
    "\n",
    "\n",
    "data_path = \"/Users/jamesmcgreivy/Desktop/opencarp_test/full-heart-simulation/data/instance_001/\"\n",
    "vtp_path = data_path + \"instance_001.vtp\"\n",
    "vtu_path = data_path + \"instance_001.vtu\"\n",
    "output_prefix = \"heart_instance_001\"\n",
    "\n",
    "vtk_to_opencarp(vtp_path, vtu_path, output_prefix, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openCARP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
